{
  "timestamp": "2025-04-15T15:11:42.493656",
  "input_parameters": {
    "model_name": "llama3-70b",
    "hidden_dim": 8192,
    "ff_dim": 28672,
    "num_layers": 80,
    "vocab_size": 128000,
    "seq_len": 1024,
    "batch_size": 1,
    "gpu_tflops": 989,
    "efficiency": 0.3,
    "precision": "fp16",
    "parallelism_strategy": "none",
    "tp_size": 1,
    "pp_size": 1,
    "num_gpus": 1,
    "gpu_id": "h200-hbm3e-141gb"
  },
  "results": {
    "model_info": {
      "name": "Llama 3 70B",
      "family": "Llama 3",
      "hidden_dimensions": 8192,
      "feedforward_dimensions": 28672,
      "num_layers": 80,
      "vocab_size": 128000,
      "default_seq_length": 8192,
      "description": "Meta's Llama 3 70B model",
      "parameter_count": 70.6
    },
    "analysis_parameters": {
      "sequence_length": 2048,
      "batch_size": 1,
      "precision": "fp16",
      "gpu_tflops": 989.0,
      "efficiency_factor": 0.3
    },
    "flops": {
      "attention": 171798691840,
      "feedforward": 962072674304,
      "prefill_total": 90709709291520,
      "per_token": 42950328320
    },
    "vram": {
      "model_weights": 111.95803833007812,
      "kv_cache": 5.0,
      "total": {
        "weights_base": 60.129913330078125,
        "kv_cache_base": 5.0,
        "activations_base": 10.0,
        "weights_with_overhead": 63.136408996582034,
        "kv_cache_with_overhead": 5.5,
        "activations_with_overhead": 11.0,
        "component_subtotal": 79.63640899658203,
        "total": 83.61822944641114
      }
    },
    "performance": {
      "tokens_per_second": 6907.9797898038505,
      "prefill_latency": 0.3057287134867543,
      "token_latency": 0.00014476012241321202,
      "time_for_1000_tokens": 0.144760122413212,
      "throughput_by_gpu": {
        "A100": 2179.261571707585,
        "H100": 5280.518423752995,
        "H200": 6907.9797898038505,
        "RTX 4090": 576.9455314841234,
        "RTX 3090": 248.65933318201928
      }
    },
    "parallelism": {
      "strategy": "none",
      "tp_size": 1,
      "pp_size": 1,
      "num_gpus": 1,
      "effective_tflops": 989.0
    },
    "overheads_used": {
      "weights": 1.05,
      "kv_cache": 1.1,
      "activations": 1.1,
      "system": 1.05
    }
  }
}