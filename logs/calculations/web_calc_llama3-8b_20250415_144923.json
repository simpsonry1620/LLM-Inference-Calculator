{
  "timestamp": "2025-04-15T14:49:23.684496",
  "input_parameters": {
    "model_name": "llama3-8b",
    "hidden_dim": 4096,
    "ff_dim": 14336,
    "num_layers": 32,
    "vocab_size": 128000,
    "seq_len": 0,
    "batch_size": 1,
    "gpu_tflops": 989,
    "efficiency": 0.3,
    "precision": "fp16",
    "parallelism_strategy": "none",
    "tp_size": 1,
    "pp_size": 1,
    "num_gpus": 1,
    "gpu_id": "h200-hbm3e-141gb"
  },
  "results": {
    "model_info": {
      "name": "Llama 3 8B",
      "family": "Llama 3",
      "hidden_dimensions": 4096,
      "feedforward_dimensions": 14336,
      "num_layers": 32,
      "vocab_size": 128000,
      "default_seq_length": 8192,
      "description": "Meta's Llama 3 8B model",
      "parameter_count": 8.0
    },
    "analysis_parameters": {
      "sequence_length": 2048,
      "batch_size": 1,
      "precision": "fp16",
      "gpu_tflops": 989.0,
      "efficiency_factor": 0.3
    },
    "flops": {
      "attention": 51539607552,
      "feedforward": 240518168576,
      "prefill_total": 9345848836096,
      "per_token": 4295098368
    },
    "vram": {
      "model_weights": 11.977554321289062,
      "kv_cache": 1.0,
      "total": {
        "weights_base": 6.0322418212890625,
        "kv_cache_base": 1.0,
        "activations_base": 2.0,
        "weights_with_overhead": 6.333853912353516,
        "kv_cache_with_overhead": 1.1,
        "activations_with_overhead": 2.2,
        "component_subtotal": 9.633853912353516,
        "total": 10.115546607971192
      }
    },
    "performance": {
      "tokens_per_second": 69078.7438561407,
      "prefill_latency": 0.03149932199560499,
      "token_latency": 1.447623312436805e-05,
      "time_for_1000_tokens": 0.014476233124368049,
      "throughput_by_gpu": {
        "A100": 21792.28319829717,
        "H100": 52804.378518950834,
        "H200": 69078.7438561407,
        "RTX 4090": 5769.367282626109,
        "RTX 3090": 2486.5553905749334
      }
    }
  }
}