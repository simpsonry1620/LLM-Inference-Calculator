# Task List: Calculator vs. Benchmark Comparison

This document outlines the tasks required to compare the `AdvancedCalculator` results against the provided benchmark sizing chart (RAG/Multi-turn use case, 5000 input / 500 output tokens).

**Goal:** Validate and potentially refine the calculator's accuracy by comparing its estimations for TTFT, Requests/s/GPU, and required GPU count against benchmark data.

## Progress Tracking Key
- `[ ]` TODO
- `[/]` IN PROGRESS
- `[x]` DONE

## Tasks

- [x] **1. Understand and Extract Benchmark Data**
    - [x] Manually transcribe the data points from the image into a structured format (e.g., table below, Python dict).
        *   Model: Llama 3.1 8B, Llama 3.1 70B
        *   GPU: H100 SXM, A100 SXM, L40S, A10G
        *   Use Case: RAG/Multi-turn convo/Chain-of-thought reasoning
        *   Tokens: 5000 Input / 500 Output
        *   TTFT Budgets: < 0.5s, < 3s
        *   Metrics: (A) Request/s/GPU, (B) # GPUs for 10 req/s
    - [x] Create a table or structure to hold the transcribed data.
        ```
        | Model        | GPU      | TTFT Budget | Req/s/GPU (A) | GPUs for 10 req/s (B) |
        |--------------|----------|-------------|---------------|-----------------------|
        | Llama 3.1 8B | H100 SXM | < 0.5s      | 4.32          | 2.32                  |
        | Llama 3.1 8B | A100 SXM | < 0.5s      | 0.13          | 76.8                  |
        | Llama 3.1 8B | L40S     | < 0.5s      | 0.077         | 129.9                 |
        | Llama 3.1 8B | A10G     | < 0.5s      | N/A           | N/A                   |
        | Llama 3.1 8B | H100 SXM | < 3s        | 5.41          | 1.85                  |
        | Llama 3.1 8B | A100 SXM | < 3s        | 1.33          | 7.49                  |
        | Llama 3.1 8B | L40S     | < 3s        | 0.67          | 15                    |
        | Llama 3.1 8B | A10G     | < 3s        | 0.33          | 35.45                 |
        | Llama 3.1 70B| H100 SXM | < 0.5s      | 0.11          | 88.4                  |
        | Llama 3.1 70B| A100 SXM | < 0.5s      | N/A           | N/A                   |
        | Llama 3.1 70B| L40S     | < 0.5s      | N/A           | N/A                   |
        | Llama 3.1 70B| A10G     | < 0.5s      | N/A           | N/A                   |
        | Llama 3.1 70B| H100 SXM | < 3s        | 0.57          | 17.6                  |
        | Llama 3.1 70B| A100 SXM | < 3s        | 0.05          | 197.5                 |
        | Llama 3.1 70B| L40S     | < 3s        | 0.0057        | 1768.3                |
        | Llama 3.1 70B| A10G     | < 3s        | N/A           | N/A                   |
        ```

- [x] **2. Map Benchmark Conditions to Calculator Inputs**
    - [x] Verify/Add model configurations (`Llama 3.1 8B`, `Llama 3.1 70B`) in `src/advanced_calculator/modules/models.py`. Ensure parameters match known specs.
        - *Status: Llama 3.1 8B and 70B definitions added.*
    - [x] Verify/Add GPU configurations (`H100 SXM`, `A100 SXM`, `L40S`, `A10G`) in `src/advanced_calculator/modules/gpus.py`. **(Always check this file first before searching externally for specs!)**
        - *Status: All required GPUs (H100 SXM, A100 SXM, L40S, A10G) confirmed or added.*
    - [x] Set `input_sequence_length = 5000`.
    - [x] Set `output_sequence_length = 500`.
    - [x] **Determine and document assumptions for:**
        - `batch_size`: 1 (Focus on single-request latency/TTFT)
        - `precision`: `fp16` (Common inference precision)
        - `efficiency_factor`: 0.3 (Conservative starting point)

- [x] **3. Run Calculator Simulations**
    - [x] Write a script (`scripts/run_benchmark_simulations.py`) or manually run `AdvancedCalculator.analyze_model_on_gpu` for each valid Model/GPU combination from the benchmark table using the inputs defined in Task 2.
    - [x] Store the results systematically (e.g., in a dictionary or JSON file) - See `logs/benchmark_simulation_results.json`.
    - [x] Note any runs skipped due to "N/A" in the benchmark or calculator limitations - See `logs/benchmark_simulation_skipped.json`.

- [/] **4. Extract and Compare Calculator Outputs**
    - [ ] For each simulation result:
        - [ ] Extract `time_to_first_token`. Compare if it falls under the 0.5s or 3s budget corresponding to the benchmark row.
        - [ ] Calculate `Request/s/GPU` (e.g., `1 / total_request_time` if `batch_size=1`). Compare with benchmark column (A).
        - [ ] Calculate `# GPUs for 10 req/s` (e.g., `10 / Calculated_Request_s_GPU`). Compare with benchmark column (B).
    - [x] Populate a comparison table with Benchmark vs. Calculator results - See `logs/comparison_results.csv` (generated by `scripts/results_to_csv.py`).

- [ ] **5. Analyze Discrepancies and Document Findings**
    - [ ] Identify significant differences between benchmark and calculator results.
    - [ ] Hypothesize reasons for discrepancies (assumptions in `batch_size`, `precision`, `efficiency_factor`, overheads, model params, benchmark methodology).
    - [ ] Document the findings, including the comparison table and analysis.
    - [ ] Suggest potential refinements to the calculator logic or parameters based on the analysis.

- [ ] **6. Refine Calculator (Optional)**
    - [ ] Implement changes to the calculator based on findings in Task 5, if deemed necessary.

- [X] NVIDIA L40S
- [X] NVIDIA L4
- [X] NVIDIA A10G
- [X] NVIDIA H200
- [X] NVIDIA B100
- [X] NVIDIA B200
- [ ] NVIDIA RTX 6000 Ada
- [ ] NVIDIA RTX A6000 